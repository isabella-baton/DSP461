{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oZOWWObz2ka"
      },
      "source": [
        "# Task for Today  \n",
        "\n",
        "***\n",
        "\n",
        "## Interview Success Prediction  \n",
        "\n",
        "Given *data about resumes*, let's try to predict whether a candidate will **pass their interview** based on their resume.\n",
        "\n",
        "We will use three models to make our predictions and PCA for dimensionality reduction to make our predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9JUBsD3z2ke"
      },
      "source": [
        "# Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVo5spMXz2kg",
        "outputId": "f63f284e-0af5-4c44-df48-d168b341ef39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vingkan/strategeion-resume-skills?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74.1k/74.1k [00:00<00:00, 21.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/vingkan/strategeion-resume-skills/versions/2\n",
            "Files in dataset directory: ['PARiS.pickle', 'skills.txt', 'resumes_pilot.csv', 'resumes_development.csv', 'fairness.py']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ML modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# kaggle api\n",
        "import os\n",
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "# download dataset from kaggle\n",
        "path = kagglehub.dataset_download(\"vingkan/strategeion-resume-skills\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "files = os.listdir(path)\n",
        "print(\"Files in dataset directory:\", files)\n",
        "\n",
        "# create dataframes\n",
        "dev_data = pd.read_csv(os.path.join(path, 'resumes_development.csv'))\n",
        "pilot_data = pd.read_csv(os.path.join(path, 'resumes_pilot.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get numbers for venn diagram of prot feats\n",
        "count1 = 0\n",
        "count2 = 0\n",
        "count3 = 0\n",
        "count4 = 0\n",
        "count5 = 0\n",
        "count6 = 0\n",
        "count7 = 0\n",
        "my_data = pilot_data\n",
        "for i in range(len(my_data)):\n",
        "  row = my_data.iloc[i]\n",
        "  if row['Female']:\n",
        "    count1 += 1\n",
        "  if row['URM']:\n",
        "    count2 += 1\n",
        "  if row['Disability']:\n",
        "    count3 += 1\n",
        "  if row['Female'] and row['URM']:\n",
        "    count4 += 1\n",
        "  if row['Female'] and row['Disability']:\n",
        "    count5 += 1\n",
        "  if row['URM'] and row['Disability']:\n",
        "    count6 += 1\n",
        "  if row['Female'] and row['URM'] and row['Disability']:\n",
        "    count7 += 1\n",
        "print(count1, count2, count3, count4, count5, count6, count7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5lwIuD7X0VS",
        "outputId": "e63f28eb-01bb-4c73-ca0e-79867086d798"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "976 930 872 901 763 791 762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpzBpBWpz2kg"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8TX-W6Tz2kh"
      },
      "outputs": [],
      "source": [
        "# data transformations\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def preprocess_inputs(data, seed=1):\n",
        "    df = data.copy()\n",
        "\n",
        "    # drop index column\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "    # split df into X, y, and Hara\n",
        "    y = df['Interview']\n",
        "    X = df.drop('Interview', axis=1)\n",
        "\n",
        "    # train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=seed)\n",
        "\n",
        "    # scale X\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train_scaled = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
        "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGtDw64AG6oT"
      },
      "source": [
        "# Measuring bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f9jthoaVG3oB"
      },
      "outputs": [],
      "source": [
        "def bias_loss(data):\n",
        "\n",
        "  prot_feats = ['Female', 'URM', 'Disability']\n",
        "  unprot_feat = 'Veteran'\n",
        "\n",
        "  # init state\n",
        "  sum_loss = 0\n",
        "  loss_n = 0\n",
        "  output = {'Female': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}},\n",
        "            'URM': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}},\n",
        "            'Disability': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}}}\n",
        "\n",
        "  # iterate\n",
        "  for prot_feat in prot_feats:\n",
        "    for unprot_name, unprot_value in [('Veteran', 1), ('Civilian', 0)]:\n",
        "      total = data[( data[unprot_feat] == unprot_value)]\n",
        "      # get matching applicants\n",
        "      pos_total = total[( total[prot_feat] == 1 )]\n",
        "      neg_total = total[( total[prot_feat] == 0 )]\n",
        "\n",
        "      # get matching accepted applicants\n",
        "      pos_hired = pos_total[( pos_total['Interview'] == 1 )]\n",
        "      neg_hired = neg_total[( neg_total['Interview'] == 1 )]\n",
        "\n",
        "      # get lengths\n",
        "      pos_total = len(pos_total)\n",
        "      neg_total = len(neg_total)\n",
        "      pos_hired = len(pos_hired)\n",
        "      neg_hired = len(neg_hired)\n",
        "\n",
        "      # get loss for this feature\n",
        "      pos_rate = pos_hired / pos_total # female acceptance rate\n",
        "      neg_rate = neg_hired / neg_total # male acceptance rate\n",
        "      rate_diff = neg_rate - pos_rate\n",
        "      sum_loss += rate_diff\n",
        "      loss_n += 1\n",
        "\n",
        "      output[prot_feat][unprot_name]['pos_rate'] = pos_rate\n",
        "      output[prot_feat][unprot_name]['neg_rate'] = neg_rate\n",
        "      output[prot_feat][unprot_name]['rate_diff'] = rate_diff\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZip_le_fiNc"
      },
      "source": [
        "# Custom Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5jqUp6MrfmZW"
      },
      "outputs": [],
      "source": [
        "# base classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "class UnbiasedRegression():\n",
        "  base_model = None\n",
        "\n",
        "  def __init__(self, random_state):\n",
        "     self.base_model = LogisticRegression(random_state=random_state)\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    self.base_model.fit(X_train, y_train)\n",
        "\n",
        "  def predict(self, X_test_scaled, X_test):\n",
        "    proba = self.base_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    for i in range(len(X_test)):\n",
        "      row = X_test.iloc[i]\n",
        "      if row['Veteran']:\n",
        "        if row['Female']:\n",
        "          proba[i] += 0.499\n",
        "      elif row['Female']:\n",
        "        proba[i] += 0.38\n",
        "    return np.clip(proba, 0, 1).round(0)\n",
        "\n",
        "  def score(self, X_test_scaled, y_test, X_test):\n",
        "    return np.mean((self.predict(X_test_scaled, X_test) == y_test).astype(int))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biased Training/Results"
      ],
      "metadata": {
        "id": "iJpsoO-w-K-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trials = 100\n",
        "sum_acc = 0\n",
        "sum_male_acc = 0\n",
        "sum_rate = 0\n",
        "sum_bias = {'Female': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}},\n",
        "            'URM': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}},\n",
        "            'Disability': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}}}\n",
        "\n",
        "for r_state in range(trials):\n",
        "\n",
        "  # preprocess\n",
        "  X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test  = preprocess_inputs(dev_data, r_state)\n",
        "\n",
        "  # train model\n",
        "  model = LogisticRegression(random_state=r_state)\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # find accuracy\n",
        "  acc = model.score(X_test_scaled, y_test)\n",
        "  sum_acc += acc\n",
        "\n",
        "  # find male accuracy\n",
        "  male_ixs = X_test.index[X_test['Female'] == 0].tolist()\n",
        "  male_X_test_scaled = X_test_scaled.loc[male_ixs]\n",
        "  male_X_test = X_test.loc[male_ixs]\n",
        "  male_y_test = y_test.loc[male_ixs]\n",
        "  male_acc = model.score(male_X_test_scaled, male_y_test)\n",
        "  sum_male_acc += male_acc\n",
        "\n",
        "  # find bias\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "  X_test['Interview'] = y_pred\n",
        "  bias = bias_loss(X_test)\n",
        "\n",
        "  for prot_feat in ['Female', 'URM', 'Disability']:\n",
        "    for vet_status, _ in [('Veteran', 1), ('Civilian', 0)]:\n",
        "      for rate in ['pos_rate', 'neg_rate', 'rate_diff']:\n",
        "        sum_bias[prot_feat][vet_status][rate] += bias[prot_feat][vet_status][rate]\n",
        "\n",
        "  # find acceptance rate\n",
        "  sum_rate += np.mean(y_pred)\n",
        "\n",
        "avg_acc = sum_acc / trials * 100\n",
        "avg_male_acc = sum_male_acc / trials * 100\n",
        "avg_rate = sum_rate / trials * 100\n",
        "print('Accuracy: {:.2f}%'.format(avg_acc))\n",
        "print('Male Accuracy:   {:.2f}%'.format(avg_male_acc))\n",
        "print('Acceptance rate: {:.2f}%'.format(avg_rate))\n",
        "\n",
        "for prot_feat in ['Female', 'URM', 'Disability']:\n",
        "  for vet_status in ['Veteran', 'Civilian']:\n",
        "    group = sum_bias[prot_feat][vet_status]\n",
        "    pos_rate = group['pos_rate'] / trials * 100\n",
        "    neg_rate = group['neg_rate'] / trials * 100\n",
        "    rate_diff = group['rate_diff'] / trials * 100\n",
        "    print(prot_feat, vet_status, '{:.2f}% - {:.2f}% = {:.2f}%'.format(neg_rate, pos_rate, rate_diff))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGlRkWV-KAs",
        "outputId": "29fcd71b-7a59-419d-84c6-571ac2cb3ccd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.33%\n",
            "Male Accuracy:   97.25%\n",
            "Acceptance rate: 36.31%\n",
            "Female Veteran 95.89% - 71.08% = 24.81%\n",
            "Female Civilian 10.83% - 2.86% = 7.96%\n",
            "URM Veteran 95.62% - 71.72% = 23.90%\n",
            "URM Civilian 9.95% - 3.39% = 6.56%\n",
            "Disability Veteran 97.64% - 74.46% = 23.19%\n",
            "Disability Civilian 9.23% - 3.44% = 5.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iot6HnEz2ki"
      },
      "source": [
        "# Unbiased Training/Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umahB_rSz2ki",
        "outputId": "ed2351b6-ba4e-4c20-fe0d-0650ba25f6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:        88.54%\n",
            "Male Accuracy:   97.25%\n",
            "Acceptance rate: 44.87%\n",
            "Female Veteran Bias:   95.89% - 94.80% = 1.09%\n",
            "Female Civilian Bias:   10.83% - 8.79% = 2.04%\n",
            "URM Veteran Bias:   95.62% - 94.92% = 0.70%\n",
            "URM Civilian Bias:   10.10% - 10.08% = 0.02%\n",
            "Disability Veteran Bias:   97.64% - 94.74% = 2.90%\n",
            "Disability Civilian Bias:   10.14% - 9.97% = 0.17%\n"
          ]
        }
      ],
      "source": [
        "trials = 100\n",
        "sum_acc = 0\n",
        "sum_male_acc = 0\n",
        "sum_rate = 0\n",
        "sum_bias = {'Female': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}},\n",
        "            'URM': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}},\n",
        "            'Disability': {\n",
        "              'Veteran': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0},\n",
        "              'Civilian': {'pos_rate': 0, 'neg_rate': 0, 'rate_diff': 0}}}\n",
        "\n",
        "for r_state in range(trials):\n",
        "\n",
        "  # preprocess\n",
        "  X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test  = preprocess_inputs(dev_data, r_state)\n",
        "\n",
        "  # train model\n",
        "  model = UnbiasedRegression(random_state=r_state)\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # find accuracy\n",
        "  acc = model.score(X_test_scaled, y_test, X_test)\n",
        "  sum_acc += acc\n",
        "\n",
        "  # find male accuracy\n",
        "  male_ixs = X_test.index[X_test['Female'] == 0].tolist()\n",
        "  male_acc = model.score(X_test_scaled.loc[male_ixs], y_test.loc[male_ixs], X_test.loc[male_ixs])\n",
        "  sum_male_acc += male_acc\n",
        "\n",
        "  # find bias\n",
        "  y_pred = model.predict(X_test_scaled, X_test)\n",
        "  X_test['Interview'] = y_pred\n",
        "  bias = bias_loss(X_test)\n",
        "\n",
        "  for prot_feat in ['Female', 'URM', 'Disability']:\n",
        "    for vet_status, _ in [('Veteran', 1), ('Civilian', 0)]:\n",
        "      for rate in ['pos_rate', 'neg_rate', 'rate_diff']:\n",
        "        sum_bias[prot_feat][vet_status][rate] += bias[prot_feat][vet_status][rate]\n",
        "\n",
        "  # find acceptance rate\n",
        "  sum_rate += np.mean(y_pred)\n",
        "\n",
        "avg_acc = sum_acc / trials * 100\n",
        "avg_male_acc = sum_male_acc / trials * 100\n",
        "avg_rate = sum_rate / trials * 100\n",
        "print('Accuracy:        {:.2f}%'.format(avg_acc))\n",
        "print('Male Accuracy:   {:.2f}%'.format(avg_male_acc))\n",
        "print('Acceptance rate: {:.2f}%'.format(avg_rate))\n",
        "\n",
        "\n",
        "for prot_feat in ['Female', 'URM', 'Disability']:\n",
        "  for vet_status in ['Veteran', 'Civilian']:\n",
        "    group = sum_bias[prot_feat][vet_status]\n",
        "    pos_rate = group['pos_rate'] / trials * 100\n",
        "    neg_rate = group['neg_rate'] / trials * 100\n",
        "    rate_diff = group['rate_diff'] / trials * 100\n",
        "    print(prot_feat, vet_status, 'Bias:   {:.2f}% - {:.2f}% = {:.2f}%'.format(neg_rate, pos_rate, rate_diff))\n",
        "\n",
        "# TODO: implement dimensionality reduction, find best n_components for max accuracy\n",
        "# TODO: find best weights for min bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NA1vm-Sz2kj"
      },
      "source": [
        "# Training/Results With Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nToD5YShz2kj"
      },
      "outputs": [],
      "source": [
        "n_components = 5\n",
        "\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(X_train)\n",
        "\n",
        "X_train_reduced = pd.DataFrame(pca.transform(X_train), index=X_train.index, columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])\n",
        "X_test_reduced = pd.DataFrame(pca.transform(X_test), index=X_test.index, columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwOo7sNJz2kj"
      },
      "outputs": [],
      "source": [
        "X_train_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-gJ0N1-z2kj"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"      Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"      Random Forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_reduced, y_train)\n",
        "    print(name + \" trained.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56CV8-Ncz2kj"
      },
      "outputs": [],
      "source": [
        "for name, model in models.items():\n",
        "    print(name + \" Accuracy: {:.2f}%\".format(model.score(X_test_reduced, y_test) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1KYVxNvz2kk"
      },
      "source": [
        "# Data Every Day  \n",
        "\n",
        "This notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n",
        "\n",
        "***\n",
        "\n",
        "Check it out!  \n",
        "https://youtu.be/BhlR-kHxc3E"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 102606,
          "sourceId": 243457,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30066,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
